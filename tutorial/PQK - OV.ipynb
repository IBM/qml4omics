{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eac8c15",
   "metadata": {},
   "source": [
    "# Projected Quantum Kernel tutorial on OV cancer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7c94b",
   "metadata": {},
   "source": [
    "#### Download data from: https://ibm.biz/DataTutorialISMB2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed371d13",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "591b3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "dir_home = 'qbiocode/'\n",
    "sys.path.append( dir_home )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "292ebac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qbiocode import pqk\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5558c37",
   "metadata": {},
   "source": [
    "### Dataset preparation\n",
    "\n",
    "First, we download the..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 5004)\n"
     ]
    }
   ],
   "source": [
    "def declare_hyperparams(param_list): \n",
    "\n",
    "    param_list.extend([x*0.001 for x in list(range(1,10, 2))])\n",
    "    param_list.extend([x*0.01 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*0.1 for x in list(range(1,10,2))])\n",
    "    param_list.extend(list(range(1,10,2)))\n",
    "    param_list.extend([x*0.1 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*10 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*100 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*1000 for x in list(range(1,10,2))])\n",
    "\n",
    "    return param_list\n",
    "\n",
    "\n",
    "def run_model(model, x_train, x_test, y_train, y_test, \n",
    "                param_grid, cv, verbose=1, n_jobs=-1, scoring='f1_weighted'):\n",
    "    grid_search =  GridSearchCV(model, \n",
    "                                param_grid, \n",
    "                                cv=cv, \n",
    "                                verbose=verbose,\n",
    "                                n_jobs=n_jobs, \n",
    "                                scoring='f1_weighted')\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    print(f\"The best parameters are {grid_search.best_params_} with a score of {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    f1_score = best_svc.score(x_test, y_test)\n",
    "    print(f\"Test F1 with best model: {f1_score:.4f}\")\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components)\n",
    "scaler = StandardScaler()\n",
    "pqk_args = {\n",
    "           'seed': 1234, \n",
    "           'backend': 'simulator',\n",
    "           }\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "svc = SVC()\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "res_dict = {}\n",
    "\n",
    "\n",
    "for data in ['mirna', 'methy', 'exp', 'integrated']:\n",
    "    print(data)\n",
    "    df = pd.read_csv('OV/OV_'+data+'.csv')\n",
    "    print(df.shape)\n",
    "    samples = df['sampleID'].tolist()\n",
    "    outcome = np.asarray(df['3y_survival'])\n",
    "    df.drop(columns=['sampleID','3y_survival'], inplace=True)\n",
    "\n",
    "    X = df.values\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, outcome, test_size=0.2, stratify=outcome, random_state=42)\n",
    "\n",
    "    num_train = x_train.shape[0]\n",
    "    num_test = x_test.shape[0]\n",
    "\n",
    "    # Flatten images to 1D arrays\n",
    "    x_train = np.reshape(x_train, (num_train, -1))\n",
    "    x_test = np.reshape(x_test, (num_test, -1))\n",
    "\n",
    "    # Run PCA\n",
    "    \n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    x_test = pca.fit_transform(x_test)\n",
    "\n",
    "    # Normalize each feature in dataset\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "    print(f'New number of features per datapoint:', len(x_train[0]))\n",
    "\n",
    "    x_train_prj, x_test_prj = pqk(x_train, \n",
    "                                  x_test, \n",
    "                                  args=pqk_args, \n",
    "                                  store=False, \n",
    "                                  encoding='ZZ', \n",
    "                                  entanglement='pairwise',  \n",
    "                                  reps= 8)\n",
    "    \n",
    "    \n",
    "    new_C_range = [] \n",
    "    new_C_range = declare_hyperparams(new_C_range)\n",
    "    \n",
    "    new_gamma_range = ['auto', 'scale']\n",
    "    new_gamma_range = declare_hyperparams(new_gamma_range)\n",
    "\n",
    "    param_grid = dict(C=new_C_range, gamma=new_gamma_range, kernel=kernel)\n",
    "\n",
    "    f1_score_q = run_model(model=svc, \n",
    "                           x_train=x_train_prj, \n",
    "                           y_train=y_train,\n",
    "                           x_test=x_test_prj, \n",
    "                           y_test=y_test, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=cv\n",
    "                           )\n",
    "    \n",
    "    f1_score_c = run_model(model=svc, \n",
    "                           x_train=x_train, \n",
    "                           y_train=y_train,\n",
    "                           x_test=x_test, \n",
    "                           y_test=y_test, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=cv\n",
    "                           )\n",
    "    \n",
    "    res_dict[data] = [f1_score_q, f1_score_c]\n",
    "    \n",
    "\n",
    "res_df = pd.DataFrame.from_dict(res_dict).T\n",
    "res_df.columns = ['F1_Q', 'F1_C']\n",
    "res_df.to_csv('PQK_OV_results.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac79abf",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc2d4ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 5004)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('OV/OV_methy.csv')\n",
    "print(df.shape)\n",
    "samples = df['sampleID'].tolist()\n",
    "outcome = np.asarray(df['3y_survival'])\n",
    "df.drop(columns=['sampleID','3y_survival'], inplace=True)\n",
    "\n",
    "X = df.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, outcome, test_size=0.2, stratify=outcome, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aab1b6",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc9099f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_hyperparams(param_list): \n",
    "\n",
    "    param_list.extend([x*0.001 for x in list(range(1,10, 2))])\n",
    "    param_list.extend([x*0.01 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*0.1 for x in list(range(1,10,2))])\n",
    "    param_list.extend(list(range(1,10,2)))\n",
    "    param_list.extend([x*0.1 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*10 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*100 for x in list(range(1,10,2))])\n",
    "    param_list.extend([x*1000 for x in list(range(1,10,2))])\n",
    "\n",
    "    return param_list\n",
    "\n",
    "\n",
    "def run_model(model, x_train, x_test, y_train, y_test, \n",
    "                param_grid, cv, verbose=1, n_jobs=-1, scoring='f1_weighted'):\n",
    "    grid_search =  GridSearchCV(model, \n",
    "                                param_grid, \n",
    "                                cv=cv, \n",
    "                                verbose=verbose,\n",
    "                                n_jobs=n_jobs, \n",
    "                                scoring='f1_weighted')\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    print(f\"The best parameters are {grid_search.best_params_} with a score of {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    f1_score = best_svc.score(x_test, y_test)\n",
    "    print(f\"Test F1 with best model: {f1_score:.4f}\")\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components)\n",
    "scaler = StandardScaler()\n",
    "pqk_args = {\n",
    "           'seed': 1234, \n",
    "           'backend': 'simulator',\n",
    "           }\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "svc = SVC()\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "res_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3d81e",
   "metadata": {},
   "source": [
    "We use PCA to reduce the dimensionality of the dataset. Here, we reduce the dataset dimension to 10, which will correspond to the number of qubits that we have in our quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd13cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of features per datapoint: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use PCA to transform each image to an n-dimensional vector\n",
    "n_components = 10\n",
    "\n",
    "# # Convert tensors to numpy arrays\n",
    "# x_train = x_train.numpy()\n",
    "# x_test = x_test.numpy()\n",
    "\n",
    "# Number of train and test samples\n",
    "num_train = x_train.shape[0]\n",
    "num_test = x_test.shape[0]\n",
    "\n",
    "# Flatten images to 1D arrays\n",
    "x_train = np.reshape(x_train, (num_train, -1))\n",
    "x_test = np.reshape(x_test, (num_test, -1))\n",
    "\n",
    "# Run PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.fit_transform(x_test)\n",
    "\n",
    "# Normalize each feature in dataset\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "\n",
    "print(f'New number of features per datapoint:', len(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3b497",
   "metadata": {},
   "source": [
    "### Project the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c0c57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqk_args = {\n",
    "           'seed': 1234, \n",
    "           'backend': 'simulator',\n",
    "           }\n",
    "\n",
    "x_train_prj, x_test_prj = pqk(x_train, x_test, args=pqk_args, store=False, encoding='ZZ', entanglement='pairwise',  reps= 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d5de8",
   "metadata": {},
   "source": [
    "### Define the projected quantum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d47d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "new_C_range = [] \n",
    "new_C_range = declare_hyperparams(new_C_range)\n",
    "print(len(new_C_range))\n",
    "new_gamma_range = ['auto', 'scale']\n",
    "new_gamma_range = declare_hyperparams(new_gamma_range)\n",
    "print(len(new_gamma_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Range of 'C' and 'gamma' values as SVC hyperparameters\n",
    "# Define the hyperparameter ranges #[7.4][1.3]#\n",
    "#C_range = [range(0.01, 1, 5)]\n",
    "#C_range.extend([x * 0.01 for x in range(1,11)])\n",
    "#C_range.extend([x * 0.25 for x in range(1, 60)])\n",
    "#C_range.extend()\n",
    "#C_range.extend([20, 50, 100, 200, 500, 700, 1000, 1100, 1200, 1300, 1400, 1500, 1700, 2000])\n",
    "\n",
    "gamma_range = ['auto', 'scale', 0.001, 0.005, 0.007]\n",
    "gamma_range.extend([x * 0.01 for x in range(1,11)])\n",
    "gamma_range.extend([x * 0.25 for x in range(1, 60)])\n",
    "gamma_range.extend([20, 50, 100])\n",
    "\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=new_C_range, gamma=new_gamma_range, kernel=kernel)\n",
    "\n",
    "# Support vector classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Define the cross validation\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Grid search for hyperparameter tuning (q: quantum)\n",
    "grid_search_q = GridSearchCV(svc, param_grid, cv=cv, verbose=1, n_jobs=-1, scoring='f1_weighted')\n",
    "grid_search_q.fit(x_train_prj, y_train)\n",
    "\n",
    "# Best model with best parameters\n",
    "best_svc_q = grid_search_q.best_estimator_\n",
    "print(f\"The best parameters are {grid_search_q.best_params_} with a score of {grid_search_q.best_score_:.4f}\")\n",
    "\n",
    "# Test accuracy\n",
    "F1_q = best_svc_q.score(x_test_prj, y_test)\n",
    "print(f\"Test F1 with best model: {F1_q:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babdf9d",
   "metadata": {},
   "source": [
    "### Classical benchmarking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684502d6",
   "metadata": {},
   "source": [
    "We can run a classical SVM without doing a quantum projection. This result is our classical benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed581ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6720 candidates, totalling 33600 fits\n",
      "The best parameters are {'C': 300, 'gamma': 5, 'kernel': 'sigmoid'} with a score of 0.6068\n",
      "Test F1 with best model: 0.5862\n"
     ]
    }
   ],
   "source": [
    "# Support vector classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Grid search for hyperparameter tuning (c: classical)\n",
    "grid_search_c = GridSearchCV(svc, param_grid, cv=cv, verbose=1, n_jobs=-1, scoring='f1_weighted')\n",
    "grid_search_c.fit(x_train, y_train)\n",
    "\n",
    "# Best model with best parameters\n",
    "best_svc_c = grid_search_c.best_estimator_\n",
    "print(f\"The best parameters are {grid_search_c.best_params_} with a score of {grid_search_c.best_score_:.4f}\")\n",
    "\n",
    "# Test accuracy\n",
    "F1_c = best_svc_c.score(x_test, y_test)\n",
    "print(f\"Test F1 with best model: {F1_c:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
